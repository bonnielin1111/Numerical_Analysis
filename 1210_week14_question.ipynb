{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1210_week14_question.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"DIMGH0wiQTq9","colab_type":"code","outputId":"e29f38e6-9eb7-4e3a-f80f-8a0bd2daeafa","executionInfo":{"status":"ok","timestamp":1544414894889,"user_tz":-480,"elapsed":818,"user":{"displayName":"林一忻","photoUrl":"","userId":"08086451903007948344"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","%matplotlib inline\n","import pylab\n","\n","h = tf.Variable(tf.random_uniform([1], 0.0, 2.0))\n","\n","\n","# Uncomment the following lines to see x.\n","print(h)\n","\n","def my_function(h):\n","  #return 10000.0-((14-2*h)*(10-2*h))\n","  return 10000.0-(140-96*h+12*h**2)\n","\n","\n","loss = my_function(h)  # Create an operation that calculates loss.\n","optimizer = tf.train.GradientDescentOptimizer(0.000001)  # Create an optimizer.\n","train = optimizer.minimize(loss)  # Create an operation that minimizes loss.\n","init = tf.initialize_all_variables()  # Create an operation initializes all the variables.\n","\n","sess = tf.Session()\n","sess.run(init)\n","# y_initial_values = sess.run(y)  # Save initial values for plotting later.\n","\n","# Uncomment the following line to see the initial W and b values.\n","print(sess.run([h]))\n","\n","for step in range(15):\n","    sess.run(train)\n","    # Uncomment the following two lines to watch training happen real time.\n","    # if step % 20 == 0:\n","    print(step, sess.run([h]))\n","    \n","print(sess.run([h]))\n"],"execution_count":58,"outputs":[{"output_type":"stream","text":["<tf.Variable 'Variable_3:0' shape=(1,) dtype=float32_ref>\n","[array([1.3454182], dtype=float32)]\n","0 [array([1.3453546], dtype=float32)]\n","1 [array([1.3452909], dtype=float32)]\n","2 [array([1.3452272], dtype=float32)]\n","3 [array([1.3451636], dtype=float32)]\n","4 [array([1.3450999], dtype=float32)]\n","5 [array([1.3450361], dtype=float32)]\n","6 [array([1.3449724], dtype=float32)]\n","7 [array([1.3449086], dtype=float32)]\n","8 [array([1.3448448], dtype=float32)]\n","9 [array([1.344781], dtype=float32)]\n","10 [array([1.3447173], dtype=float32)]\n","11 [array([1.3446535], dtype=float32)]\n","12 [array([1.3445897], dtype=float32)]\n","13 [array([1.3445259], dtype=float32)]\n","14 [array([1.3444622], dtype=float32)]\n","[array([1.3444622], dtype=float32)]\n"],"name":"stdout"}]},{"metadata":{"id":"qsPuIZaSTQNj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"a37d2d0d-7441-4a70-b75c-bc3c9d505b5d","executionInfo":{"status":"ok","timestamp":1544414894889,"user_tz":-480,"elapsed":818,"user":{"displayName":"林一忻","photoUrl":"","userId":"08086451903007948344"}}},"cell_type":"code","source":["H=sess.run([h])\n","print(H)\n","\n","A=(14-2*h)*(10-2*h)*h\n","print(sess.run([A]))"],"execution_count":59,"outputs":[{"output_type":"stream","text":["[array([1.3444622], dtype=float32)]\n","[array([111.181816], dtype=float32)]\n"],"name":"stdout"}]},{"metadata":{"id":"sLZaFRzI0aKM","colab_type":"code","outputId":"4a96fe45-ca17-4188-d02c-6ff26ce5bf64","executionInfo":{"status":"ok","timestamp":1544414897857,"user_tz":-480,"elapsed":3777,"user":{"displayName":"林一忻","photoUrl":"","userId":"08086451903007948344"}},"colab":{"base_uri":"https://localhost:8080/","height":2397}},"cell_type":"code","source":["import numpy as np\n","\n","import multiprocessing\n","from collections import OrderedDict\n","import os\n","import time\n","\n","\n","def eval_iter(arg_lst, l_lst):\n","    for c_i, args in enumerate(arg_lst):\n","        yield c_i, args, l_lst\n","\n","\n","def eval_func(c_i, args, l_lst):\n","    assert len(args) == 3\n","    x = args[0]\n","    y = args[1]\n","    z = args[2]\n","    res = x*y+z*((x+2*x*y+3.5)-200)\n","    print(f\"Eval {x}, {y}, {z}: {res}\")\n","    l_lst[c_i] = res\n","\n","\n","if __name__ == '__main__':\n","\n","    generation_num = 20\n","    child_num = 5\n","\n","    space = OrderedDict((\n","        ('x', (10., 12.)),\n","        ('y', (5., 7.)),\n","        ('z', (0., 2.))\n","    ))\n","\n","    params = OrderedDict([(nm, []) for nm in space.keys()])\n","    for nm, v_range in space.items():\n","        params[nm] = np.random.uniform(v_range[0], v_range[1], size=child_num)\n","\n","    arg_list = []\n","    for c_n in range(child_num):\n","        arg_list.append([val[c_n] for val in params.values()])\n","\n","    manager = multiprocessing.Manager()\n","    loss_lst = manager.list([np.inf for i in range(child_num)])\n","\n","    for r_n in range(generation_num):\n","        with multiprocessing.Pool(os.cpu_count()) as pool:\n","            pool.starmap(eval_func, eval_iter(arg_list, loss_lst))\n","\n","        fittest_idx = int(np.argmin(loss_lst))\n","        base_args = arg_list[fittest_idx]\n","        print(f\"Best {base_args}\\n\")\n","\n","        # mutate offspring from fittest individual\n","        params = OrderedDict([(nm, []) for nm in space.keys()])\n","        for s_i, (nm, v_range) in enumerate(space.items()):\n","            std = (v_range[1] - v_range[0]) / 2\n","            noise = np.random.normal(0, std, size=child_num)\n","            new_param = base_args[s_i] + noise\n","            params[nm] = np.clip(new_param, v_range[0], v_range[1])\n","\n","        arg_list = []\n","        for c_n in range(child_num):\n","            arg_list.append([val[c_n] for val in params.values()])\n","\n","        loss_lst = manager.list([np.inf for i in range(child_num)])"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Eval 11.321748429248265, 5.270997147779575, 1.604354066175953: -45.92881104983422\n","Eval 11.085929817020881, 6.9485379177777435, 1.1006489852238988: 42.52338757287761\n","Eval 11.012126147767367, 6.063580530242118, 0.30550381485462386: 50.90442036743052\n","Eval 10.395971476567937, 6.218558877126279, 0.15854463087689297: 55.64134034105699\n","Eval 11.84546811621248, 6.310585239202909, 0.35032792162920345: 62.437508731147034\n","Best [11.321748429248265, 5.270997147779575, 1.604354066175953]\n","\n","Eval 10.0, 6.929686186630017, 1.4669138038689142: -0.977516082306181\n","Eval 11.083657722630424, 5.960511089140036, 2.0: -40.51136073488297\n","Eval 11.681533589889895, 5.585331916229841, 2.0: -43.41072086960533\n","Eval 10.256957120209625, 5.091646873271497, 0.5384555430333164: 8.18267487914408\n","Eval 11.32036026748605, 6.09906508579416, 0.4749380512192154: 46.67763587330815\n","Best [11.681533589889895, 5.585331916229841, 2.0]\n","\n","Eval 12.0, 7.0, 2.0: 51.0\n","Eval 12.0, 5.4985730572535, 1.8687783151342139: -32.191984209382596\n","Eval 12.0, 5.604848447386729, 2.0: -32.70909315679626\n","Eval 12.0, 5.332126731613774, 2.0: -49.07239610317356\n","Eval 11.803746965075884, 6.709450915677997, 2.0: 26.590798346450583\n","Best [12.0, 5.332126731613774, 2.0]\n","\n","Eval 12.0, 5.0, 0.6179049864190269: 20.145128375972767\n","Eval 12.0, 5.463727898564951, 2.0: -41.17632608610295\n","Eval 12.0, 5.352226801944374, 2.0: -47.8663918833376\n","Eval 11.89108834144887, 5.934279686550859, 0.5634254977059183: 46.067966131243665\n","Eval 12.0, 5.715919192568615, 1.7902808753654154: -16.121371619942494\n","Best [12.0, 5.352226801944374, 2.0]\n","\n","Eval 10.578538482448408, 6.3223012823823606, 2.0: -37.439385968529564\n","Eval 12.0, 6.016003965035267, 2.0: -8.039762097883965\n","Eval 11.950181244616651, 6.068186852827726, 0.720378017724403: 44.048067840015335\n","Eval 11.111738117508159, 5.52721643838555, 2.0: -63.691615854351674\n","Eval 12.0, 6.406203850178198, 2.0: 15.372231010691863\n","Best [11.111738117508159, 5.52721643838555, 2.0]\n","\n","Eval 12.0, 6.253172161428896, 2.0: 6.190329685733772\n","Eval 11.305744698561464, 5.66635917925652, 2.0: -50.07645934775465\n","Eval 11.488632142954517, 5.943503592152335, 2.0: -28.609103661256214\n","Eval 12.0, 5.791929875936128, 0.8557844038077376: 30.570374147287303\n","Eval 10.0, 5.0, 1.642020888693112: -92.0348068719542\n","Best [10.0, 5.0, 1.642020888693112]\n","\n","Eval 10.0, 5.0, 1.2707193776584065: -59.91722616745216\n","Eval 10.708958597543708, 5.8128131085174495, 1.632512933922237: -37.811936834616795\n","Eval 12.0, 5.50392790730233, 2.0: -38.76432556186019\n","Eval 10.0, 5.0, 1.0928361810470806: -44.53032966057248\n","Eval 10.0, 6.19585490538629, 0.4014730168411349: 36.83320262849881\n","Best [10.0, 5.0, 1.2707193776584065]\n","\n","Eval 10.0, 5.746814043591345, 1.2225898753212863: -30.024938010527237\n","Eval 10.449746002599188, 5.50076245527698, 0.7950140691366666: 0.9663154764985578\n","Eval 10.0, 6.831512968841036, 0.7769163927824134: 29.570510694455344\n","Eval 10.967465537830563, 5.0, 1.381489045239194: -49.95950126028441\n","Eval 10.0, 5.848649377160304, 0.3617066003100625: 33.33811446614074\n","Best [10.967465537830563, 5.0, 1.381489045239194]\n","\n","Eval 10.310015414359377, 5.0, 0.6816240445953414: -5.085949218852221\n","Eval 10.468320514212703, 5.380978302698101, 2.0: -90.41433120823467\n","Eval 10.45949260570453, 5.3704763737717185, 1.0010430731516287: -17.60000352550945\n","Eval 11.949770564972374, 5.0, 2.0: -70.35619474574591\n","Eval 10.0, 5.109128199951399, 2.0: -117.54359000243005\n","Best [10.0, 5.109128199951399, 2.0]\n","\n","Eval 10.0, 5.0, 1.340864587612739: -65.98478682850192\n","Eval 10.25524227678802, 5.0, 1.392667049353445: -65.27934579180202\n","Eval 11.818723468726658, 5.724333145042552, 2.0: -31.091000641925277\n","Eval 10.0, 6.6993758494171, 2.0: -38.03120752914498\n","Eval 10.476480380761108, 5.0, 2.0: -110.13502971945007\n","Best [10.476480380761108, 5.0, 2.0]\n","\n","Eval 10.440034393199197, 5.0, 2.0: -111.11907138362167\n","Eval 10.211197354184677, 6.432028287639199, 2.0: -44.18405412771865\n","Eval 10.0, 5.0, 0.7021333065040363: -10.734531012599135\n","Eval 11.099327149503162, 5.0, 1.5905698388954237: -62.85353263907362\n","Eval 10.341890780426333, 5.402064484482896, 2.0: -92.97841400243638\n","Best [10.440034393199197, 5.0, 2.0]\n","\n","Eval 11.479486226835993, 6.2660361500111375, 1.9560696513913367: -8.578530360750037\n","Eval 10.855122502346834, 5.0, 2.0: -99.9116924366355\n","Eval 10.952214799066557, 5.0, 2.0: -97.290200425203\n","Eval 10.0, 5.0, 0.7920484918157895: -18.5121945420658\n","Eval 10.458822507490986, 5.0, 2.0: -110.61179229774339\n","Best [10.458822507490986, 5.0, 2.0]\n","\n","Eval 10.0, 6.3077668382880265, 2.0: -57.61165808559869\n","Eval 10.0, 5.0, 2.0: -123.0\n","Eval 10.0, 5.0, 1.1211611888387696: -46.98044283455357\n","Eval 11.423370939393308, 6.222723479766152, 2.0: -14.730865308008077\n","Eval 10.070379614127537, 5.0, 2.0: -121.0997504185565\n","Best [10.0, 5.0, 2.0]\n","\n","Eval 10.0, 5.488865069405895, 2.0: -98.55674652970524\n","Eval 11.89406783426728, 5.0, 0.8510108676894497: 3.5884945383262377\n","Eval 10.11191522237496, 6.746498751153771, 1.4199798110021966: -2.705182052421506\n","Eval 11.658938393970413, 5.0, 1.7526532457323105: -61.326832418708705\n","Eval 11.243816640789912, 7.0, 0.23758351123109755: 72.09173808598139\n","Best [10.0, 5.488865069405895, 2.0]\n","\n","Eval 10.0, 6.586763058305614, 0.6044179796131832: 32.76683778303409\n","Eval 10.0, 7.0, 2.0: -23.0\n","Eval 10.897019083068539, 5.0, 2.0: -98.78048475714942\n","Eval 11.64476727693392, 5.0, 1.8493714461406605: -68.28715169390823\n","Eval 10.0, 6.796014005666786, 2.0: -33.19929971666073\n","Best [10.897019083068539, 5.0, 2.0]\n","\n","Eval 11.495749856033052, 5.525256294028891, 2.0: -52.42367905479221\n","Eval 11.698006167408797, 5.0, 2.0: -77.15383347996244\n","Eval 10.440240619763351, 5.044607352127134, 0.21440814122548968: 35.35861794483189\n","Eval 12.0, 5.0, 1.6206687078869544: -44.533131658708555\n","Eval 10.0, 6.056909576242008, 2.0: -70.15452118789962\n","Best [11.698006167408797, 5.0, 2.0]\n","\n","Eval 12.0, 5.0, 2.0: -69.0\n","Eval 11.101634139355122, 5.0, 0.21203453575415443: 39.73661267044125\n","Eval 11.60027402713405, 5.0, 1.3535807689487336: -35.2562647484505\n","Eval 11.892210557327756, 5.451017710872753, 0.0: 64.82465036942153\n","Eval 12.0, 5.041024772597706, 1.1580573391858788: -13.062184170431777\n","Best [12.0, 5.0, 2.0]\n","\n","Eval 12.0, 5.0, 1.9863881378389376: -68.12203489061147\n","Eval 11.393129449077131, 6.452674739223397, 2.0: -2.6329481180348466\n","Eval 11.566482670078715, 5.0, 2.0: -80.7049679078747\n","Eval 11.547530234907647, 5.0, 1.2847515502471505: -31.523247369968963\n","Eval 12.0, 5.88145110623117, 1.382911895552621: 10.634857295352454\n","Best [11.566482670078715, 5.0, 2.0]\n","\n","Eval 11.878563792918904, 5.0, 2.0: -72.2787775911896\n","Eval 11.280255001876126, 5.0, 2.0: -88.43311494934457\n","Eval 10.245034887789858, 5.0, 2.0: -116.38405802967384\n","Eval 10.904757824768826, 6.425456826726748, 1.5519039699508572: -0.4801707132354096\n","Eval 10.283213244051396, 5.0, 2.0: -115.35324241061231\n","Best [10.245034887789858, 5.0, 2.0]\n","\n","Eval 10.0, 5.516348900507181, 2.0: -97.18255497464095\n","Eval 10.079437474994942, 5.706958430955785, 1.9379483935978854: -80.79755679983455\n","Eval 10.238684443691481, 6.59746688342666, 2.0: -34.775723377065745\n","Eval 10.396772394237306, 5.479528190291327, 1.9283764373825591: -82.19074576404067\n","Eval 10.334440130597578, 5.013410800889472, 2.0: -113.27715087938728\n","Best [10.334440130597578, 5.013410800889472, 2.0]\n","\n"],"name":"stdout"}]}]}